"""
å°è« DeepSeek-OCR è‡ªåŠ¨ç³»ç»Ÿå…¼å®¹æ€§æ£€æµ‹å’Œé…ç½®
è‡ªåŠ¨è¯†åˆ«ç³»ç»Ÿç¯å¢ƒï¼Œé€‰æ‹©æœ€ä½³é…ç½®æ–¹æ¡ˆ
"""

import os
import sys
import platform
import subprocess
import json
from typing import Dict, List, Optional, Tuple


class SystemCompatibility:
    """ç³»ç»Ÿå…¼å®¹æ€§æ£€æµ‹å™¨"""

    def __init__(self):
        self.os_type = platform.system()
        self.os_version = platform.version()
        self.python_version = sys.version_info
        self.architecture = platform.machine()
        self.has_cuda = False
        self.cuda_version = None
        self.gpu_info = []
        self.cpu_info = {}
        self.memory_info = {}
        self.recommended_config = {}

    def detect_all(self) -> Dict:
        """æ£€æµ‹æ‰€æœ‰ç³»ç»Ÿä¿¡æ¯"""
        print("=" * 60)
        print("ğŸ” å°è« OCR - ç³»ç»Ÿå…¼å®¹æ€§æ£€æµ‹")
        print("=" * 60)

        self._detect_os()
        self._detect_python()
        self._detect_cuda()
        self._detect_gpu()
        self._detect_cpu()
        self._detect_memory()
        self._detect_dependencies()
        self._generate_recommendation()

        return self.get_summary()

    def _detect_os(self):
        """æ£€æµ‹æ“ä½œç³»ç»Ÿ"""
        print(f"\nğŸ“± æ“ä½œç³»ç»Ÿ: {self.os_type} {self.os_version}")
        print(f"   æ¶æ„: {self.architecture}")

        if self.os_type == "Linux":
            try:
                with open("/etc/os-release", "r") as f:
                    for line in f:
                        if line.startswith("PRETTY_NAME"):
                            distro = line.split("=")[1].strip().strip('"')
                            print(f"   å‘è¡Œç‰ˆ: {distro}")
                            break
            except:
                pass

    def _detect_python(self):
        """æ£€æµ‹ Python ç‰ˆæœ¬"""
        version_str = f"{self.python_version.major}.{self.python_version.minor}.{self.python_version.micro}"
        print(f"\nğŸ Python ç‰ˆæœ¬: {version_str}")

        if self.python_version < (3, 9):
            print("   âš ï¸  è­¦å‘Š: Python ç‰ˆæœ¬è¿‡ä½ï¼Œæ¨è 3.12+")
        elif self.python_version >= (3, 12):
            print("   âœ… Python ç‰ˆæœ¬æ»¡è¶³è¦æ±‚")
        else:
            print("   âš¡ Python ç‰ˆæœ¬å¯ç”¨ï¼Œå»ºè®®å‡çº§åˆ° 3.12+")

    def _detect_cuda(self):
        """æ£€æµ‹ CUDA"""
        print(f"\nğŸ® GPU/CUDA æ£€æµ‹:")

        # æ–¹æ³•1: ä½¿ç”¨ nvidia-smi
        try:
            result = subprocess.run(
                ["nvidia-smi", "--query-gpu=driver_version", "--format=csv,noheader"],
                capture_output=True,
                text=True,
                timeout=5
            )
            if result.returncode == 0:
                driver_version = result.stdout.strip()
                print(f"   NVIDIA é©±åŠ¨: {driver_version}")
                self.has_cuda = True
        except:
            pass

        # æ–¹æ³•2: æ£€æŸ¥ CUDA å·¥å…·åŒ…
        if self.has_cuda:
            try:
                result = subprocess.run(
                    ["nvcc", "--version"],
                    capture_output=True,
                    text=True,
                    timeout=5
                )
                if result.returncode == 0:
                    for line in result.stdout.split('\n'):
                        if 'release' in line.lower():
                            self.cuda_version = line.split('release')[1].split(',')[0].strip()
                            print(f"   CUDA ç‰ˆæœ¬: {self.cuda_version}")
                            break
            except:
                pass

        # æ–¹æ³•3: æ£€æŸ¥ PyTorch CUDA
        try:
            import torch
            if torch.cuda.is_available():
                self.has_cuda = True
                cuda_version = torch.version.cuda
                print(f"   PyTorch CUDA: {cuda_version}")
                print(f"   CUDA è®¾å¤‡æ•°: {torch.cuda.device_count()}")
            else:
                print("   âš ï¸  PyTorch æ— æ³•ä½¿ç”¨ CUDA")
        except ImportError:
            print("   â„¹ï¸  PyTorch æœªå®‰è£…")

        if not self.has_cuda:
            print("   âš ï¸  æœªæ£€æµ‹åˆ° CUDAï¼Œå°†ä½¿ç”¨ CPU æ¨¡å¼ï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰")

    def _detect_gpu(self):
        """æ£€æµ‹ GPU ä¿¡æ¯"""
        if not self.has_cuda:
            return

        print(f"\nğŸ’» GPU ä¿¡æ¯:")

        try:
            result = subprocess.run(
                ["nvidia-smi", "--query-gpu=name,memory.total,memory.free",
                 "--format=csv,noheader,nounits"],
                capture_output=True,
                text=True,
                timeout=5
            )

            if result.returncode == 0:
                for line in result.stdout.strip().split('\n'):
                    parts = [p.strip() for p in line.split(',')]
                    if len(parts) == 3:
                        gpu_info = {
                            'name': parts[0],
                            'total_memory': int(parts[1]),
                            'free_memory': int(parts[2])
                        }
                        self.gpu_info.append(gpu_info)
                        print(f"   {gpu_info['name']}")
                        print(f"   â””â”€ æ˜¾å­˜: {gpu_info['total_memory']}MB "
                              f"(å¯ç”¨: {gpu_info['free_memory']}MB)")
        except Exception as e:
            print(f"   âš ï¸  æ— æ³•è·å–è¯¦ç»† GPU ä¿¡æ¯: {e}")

    def _detect_cpu(self):
        """æ£€æµ‹ CPU ä¿¡æ¯"""
        print(f"\nğŸ–¥ï¸  CPU ä¿¡æ¯:")

        try:
            cpu_count = os.cpu_count() or 0
            print(f"   æ ¸å¿ƒæ•°: {cpu_count}")
            self.cpu_info['count'] = cpu_count

            if self.os_type == "Linux":
                with open("/proc/cpuinfo", "r") as f:
                    for line in f:
                        if "model name" in line:
                            cpu_name = line.split(":")[1].strip()
                            print(f"   å‹å·: {cpu_name}")
                            self.cpu_info['name'] = cpu_name
                            break
            elif self.os_type == "Darwin":  # macOS
                result = subprocess.run(
                    ["sysctl", "-n", "machdep.cpu.brand_string"],
                    capture_output=True,
                    text=True
                )
                if result.returncode == 0:
                    cpu_name = result.stdout.strip()
                    print(f"   å‹å·: {cpu_name}")
                    self.cpu_info['name'] = cpu_name
        except:
            pass

    def _detect_memory(self):
        """æ£€æµ‹å†…å­˜ä¿¡æ¯"""
        print(f"\nğŸ’¾ å†…å­˜ä¿¡æ¯:")

        try:
            if self.os_type == "Linux":
                with open("/proc/meminfo", "r") as f:
                    for line in f:
                        if "MemTotal" in line:
                            mem_kb = int(line.split()[1])
                            mem_gb = mem_kb / 1024 / 1024
                            print(f"   æ€»å†…å­˜: {mem_gb:.1f} GB")
                            self.memory_info['total'] = mem_gb
                        elif "MemAvailable" in line:
                            mem_kb = int(line.split()[1])
                            mem_gb = mem_kb / 1024 / 1024
                            print(f"   å¯ç”¨å†…å­˜: {mem_gb:.1f} GB")
                            self.memory_info['available'] = mem_gb
                            break

            elif self.os_type == "Darwin":  # macOS
                result = subprocess.run(
                    ["sysctl", "hw.memsize"],
                    capture_output=True,
                    text=True
                )
                if result.returncode == 0:
                    mem_bytes = int(result.stdout.split()[1])
                    mem_gb = mem_bytes / 1024 / 1024 / 1024
                    print(f"   æ€»å†…å­˜: {mem_gb:.1f} GB")
                    self.memory_info['total'] = mem_gb

            elif self.os_type == "Windows":
                import ctypes
                kernel32 = ctypes.windll.kernel32
                c_ulong = ctypes.c_ulong

                class MEMORYSTATUSEX(ctypes.Structure):
                    _fields_ = [
                        ("dwLength", c_ulong),
                        ("dwMemoryLoad", c_ulong),
                        ("ullTotalPhys", ctypes.c_ulonglong),
                        ("ullAvailPhys", ctypes.c_ulonglong),
                        ("ullTotalPageFile", ctypes.c_ulonglong),
                        ("ullAvailPageFile", ctypes.c_ulonglong),
                        ("ullTotalVirtual", ctypes.c_ulonglong),
                        ("ullAvailVirtual", ctypes.c_ulonglong),
                        ("ullAvailExtendedVirtual", ctypes.c_ulonglong),
                    ]

                memoryStatus = MEMORYSTATUSEX()
                memoryStatus.dwLength = ctypes.sizeof(MEMORYSTATUSEX)
                kernel32.GlobalMemoryStatusEx(ctypes.byref(memoryStatus))

                mem_gb = memoryStatus.ullTotalPhys / 1024 / 1024 / 1024
                avail_gb = memoryStatus.ullAvailPhys / 1024 / 1024 / 1024
                print(f"   æ€»å†…å­˜: {mem_gb:.1f} GB")
                print(f"   å¯ç”¨å†…å­˜: {avail_gb:.1f} GB")
                self.memory_info['total'] = mem_gb
                self.memory_info['available'] = avail_gb

        except Exception as e:
            print(f"   âš ï¸  æ— æ³•è·å–å†…å­˜ä¿¡æ¯: {e}")

    def _detect_dependencies(self):
        """æ£€æµ‹ä¾èµ–åŒ…"""
        print(f"\nğŸ“¦ å…³é”®ä¾èµ–æ£€æµ‹:")

        dependencies = [
            ('torch', 'æ·±åº¦å­¦ä¹ æ¡†æ¶'),
            ('transformers', 'Transformers åº“'),
            ('vllm', 'vLLM æ¨ç†å¼•æ“'),
            ('PIL', 'Pillow å›¾åƒå¤„ç†'),
            ('flask', 'Flask Web æ¡†æ¶'),
            ('pdf2image', 'PDF è½¬æ¢å·¥å…·')
        ]

        for pkg_name, desc in dependencies:
            try:
                if pkg_name == 'PIL':
                    from PIL import Image
                    import PIL
                    version = PIL.__version__
                else:
                    module = __import__(pkg_name)
                    version = getattr(module, '__version__', 'unknown')

                print(f"   âœ… {desc} ({pkg_name}): {version}")
            except ImportError:
                print(f"   âŒ {desc} ({pkg_name}): æœªå®‰è£…")

        # æ£€æŸ¥ç³»ç»Ÿå·¥å…·
        print(f"\nğŸ”§ ç³»ç»Ÿå·¥å…·æ£€æµ‹:")

        tools = [
            ('poppler', 'pdfinfo', 'PDF å¤„ç†å·¥å…·'),
        ]

        for tool_name, command, desc in tools:
            try:
                result = subprocess.run(
                    [command, '--version'],
                    capture_output=True,
                    timeout=2
                )
                if result.returncode == 0:
                    print(f"   âœ… {desc}: å·²å®‰è£…")
                else:
                    print(f"   âŒ {desc}: æœªå®‰è£…")
            except:
                print(f"   âŒ {desc}: æœªå®‰è£…")

    def _generate_recommendation(self):
        """ç”Ÿæˆæ¨èé…ç½®"""
        print(f"\n" + "=" * 60)
        print("ğŸ¯ æ¨èé…ç½®æ–¹æ¡ˆ")
        print("=" * 60)

        # æ¨ç†å¼•æ“é€‰æ‹©
        if self.has_cuda and self.gpu_info:
            max_memory = max([gpu['total_memory'] for gpu in self.gpu_info])

            if max_memory >= 40000:  # 40GB+
                print("\nâœ… æ¨èä½¿ç”¨: vLLM + GPU (é«˜æ€§èƒ½)")
                self.recommended_config['engine'] = 'vllm'
                self.recommended_config['device'] = 'cuda'
                self.recommended_config['resolution'] = '1280x1280'
                self.recommended_config['batch_size'] = 4
            elif max_memory >= 24000:  # 24GB+
                print("\nâœ… æ¨èä½¿ç”¨: vLLM + GPU (æ ‡å‡†)")
                self.recommended_config['engine'] = 'vllm'
                self.recommended_config['device'] = 'cuda'
                self.recommended_config['resolution'] = '1024x1024'
                self.recommended_config['batch_size'] = 2
            elif max_memory >= 12000:  # 12GB+
                print("\nâš¡ æ¨èä½¿ç”¨: Transformers + GPU (ç»æµ)")
                self.recommended_config['engine'] = 'transformers'
                self.recommended_config['device'] = 'cuda'
                self.recommended_config['resolution'] = '768x768'
                self.recommended_config['batch_size'] = 1
            else:
                print("\nâš ï¸  GPU æ˜¾å­˜ä¸è¶³ï¼Œæ¨èä½¿ç”¨ CPU æ¨¡å¼")
                self.recommended_config['engine'] = 'transformers'
                self.recommended_config['device'] = 'cpu'
                self.recommended_config['resolution'] = '512x512'
                self.recommended_config['batch_size'] = 1
        else:
            print("\nâš¡ æ¨èä½¿ç”¨: Transformers + CPU (å…¼å®¹)")
            self.recommended_config['engine'] = 'transformers'
            self.recommended_config['device'] = 'cpu'
            self.recommended_config['resolution'] = '512x512'
            self.recommended_config['batch_size'] = 1

        # æ˜¾ç¤ºè¯¦ç»†é…ç½®
        print(f"\né…ç½®è¯¦æƒ…:")
        print(f"  - æ¨ç†å¼•æ“: {self.recommended_config['engine']}")
        print(f"  - è®¡ç®—è®¾å¤‡: {self.recommended_config['device']}")
        print(f"  - æ¨èåˆ†è¾¨ç‡: {self.recommended_config['resolution']}")
        print(f"  - æ‰¹å¤„ç†å¤§å°: {self.recommended_config['batch_size']}")

        # æ€§èƒ½é¢„ä¼°
        self._estimate_performance()

    def _estimate_performance(self):
        """é¢„ä¼°æ€§èƒ½"""
        print(f"\nğŸ“Š æ€§èƒ½é¢„ä¼°:")

        config = self.recommended_config

        if config['engine'] == 'vllm' and config['device'] == 'cuda':
            if config['resolution'] == '1280x1280':
                print(f"  - å•å›¾å¤„ç†: ~1-2 ç§’")
                print(f"  - PDF é¡µé¢: ~2500 tokens/ç§’")
                print(f"  - æ—¥å¤„ç†é‡: ~15-20 ä¸‡é¡µ")
            else:
                print(f"  - å•å›¾å¤„ç†: ~0.5-1 ç§’")
                print(f"  - PDF é¡µé¢: ~2000 tokens/ç§’")
                print(f"  - æ—¥å¤„ç†é‡: ~10-15 ä¸‡é¡µ")
        elif config['engine'] == 'transformers' and config['device'] == 'cuda':
            print(f"  - å•å›¾å¤„ç†: ~2-5 ç§’")
            print(f"  - PDF é¡µé¢: ~1000 tokens/ç§’")
            print(f"  - æ—¥å¤„ç†é‡: ~5-10 ä¸‡é¡µ")
        else:
            print(f"  - å•å›¾å¤„ç†: ~10-30 ç§’")
            print(f"  - PDF é¡µé¢: ~100 tokens/ç§’")
            print(f"  - æ—¥å¤„ç†é‡: ~1-2 ä¸‡é¡µ")
            print(f"  âš ï¸  CPU æ¨¡å¼é€Ÿåº¦è¾ƒæ…¢ï¼Œå»ºè®®ä½¿ç”¨ GPU")

    def get_summary(self) -> Dict:
        """è·å–æ£€æµ‹æ‘˜è¦"""
        return {
            'os': {
                'type': self.os_type,
                'version': self.os_version,
                'architecture': self.architecture
            },
            'python': {
                'version': f"{self.python_version.major}.{self.python_version.minor}.{self.python_version.micro}"
            },
            'cuda': {
                'available': self.has_cuda,
                'version': self.cuda_version
            },
            'gpu': self.gpu_info,
            'cpu': self.cpu_info,
            'memory': self.memory_info,
            'recommended_config': self.recommended_config
        }

    def save_config(self, filepath: str = "auto_config.json"):
        """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
        config = self.get_summary()
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        print(f"\nğŸ’¾ é…ç½®å·²ä¿å­˜åˆ°: {filepath}")

    def install_dependencies(self, auto_install: bool = False):
        """å®‰è£…ç¼ºå¤±çš„ä¾èµ–"""
        print(f"\n" + "=" * 60)
        print("ğŸ“¦ ä¾èµ–å®‰è£…")
        print("=" * 60)

        if not auto_install:
            response = input("\næ˜¯å¦è‡ªåŠ¨å®‰è£…ç¼ºå¤±çš„ä¾èµ–? (y/n): ")
            if response.lower() != 'y':
                print("å·²å–æ¶ˆå®‰è£…")
                return

        print("\næ­£åœ¨å®‰è£…ä¾èµ–...")

        # å®‰è£… Python ä¾èµ–
        try:
            subprocess.run(
                [sys.executable, "-m", "pip", "install", "-r",
                 "../config/requirements.txt"],
                check=True
            )
            print("âœ… Python ä¾èµ–å®‰è£…å®Œæˆ")
        except Exception as e:
            print(f"âŒ Python ä¾èµ–å®‰è£…å¤±è´¥: {e}")

        # å®‰è£…ç³»ç»Ÿä¾èµ–
        if self.os_type == "Linux":
            print("\nè¯·æ‰‹åŠ¨å®‰è£…ç³»ç»Ÿä¾èµ–:")
            print("  sudo apt-get install -y poppler-utils")
        elif self.os_type == "Darwin":
            print("\nè¯·æ‰‹åŠ¨å®‰è£…ç³»ç»Ÿä¾èµ–:")
            print("  brew install poppler")


def main():
    """ä¸»å‡½æ•°"""
    detector = SystemCompatibility()
    summary = detector.detect_all()

    # ä¿å­˜é…ç½®
    detector.save_config()

    print(f"\n" + "=" * 60)
    print("âœ… æ£€æµ‹å®Œæˆ")
    print("=" * 60)
    print(f"\næç¤º:")
    print(f"  1. é…ç½®æ–‡ä»¶å·²ä¿å­˜åˆ° auto_config.json")
    print(f"  2. å¯åŠ¨æœåŠ¡æ—¶å°†è‡ªåŠ¨ä½¿ç”¨æ¨èé…ç½®")
    print(f"  3. å¦‚éœ€æ‰‹åŠ¨è°ƒæ•´ï¼Œè¯·ç¼–è¾‘é…ç½®æ–‡ä»¶")
    print(f"\n" + "=" * 60)


if __name__ == "__main__":
    main()
