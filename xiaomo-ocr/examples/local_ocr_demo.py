#!/usr/bin/env python3
"""
å°è« OCR - æœ¬åœ°éƒ¨ç½²æ¼”ç¤ºï¼ˆæ— éœ€APIï¼‰
ç›´æ¥ä½¿ç”¨DeepSeek-OCRå®˜æ–¹å¼€æºä»£ç 
"""

from transformers import AutoModel, AutoTokenizer
import torch
import os
from pathlib import Path
from PIL import Image
import time
from typing import Optional, List


class LocalOCR:
    """
    æœ¬åœ°OCRå¼•æ“
    å®Œå…¨åŸºäºGitHubå¼€æºä»£ç ï¼Œæ— éœ€ä»»ä½•API
    """

    def __init__(self, model_name: str = 'deepseek-ai/DeepSeek-OCR'):
        """
        åˆå§‹åŒ–æœ¬åœ°OCR

        Args:
            model_name: æ¨¡å‹åç§°æˆ–æœ¬åœ°è·¯å¾„
        """
        self.model_name = model_name
        self.model = None
        self.tokenizer = None
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'

        print(f"ğŸ”§ åˆå§‹åŒ–å°è« OCR (æœ¬åœ°æ¨¡å¼)")
        print(f"   è®¾å¤‡: {self.device}")

    def load_model(self, use_flash_attn: bool = True):
        """
        åŠ è½½æ¨¡å‹åˆ°æœ¬åœ°

        Args:
            use_flash_attn: æ˜¯å¦ä½¿ç”¨Flash AttentionåŠ é€Ÿ
        """
        print(f"\nğŸ“¥ æ­£åœ¨åŠ è½½æ¨¡å‹: {self.model_name}")
        print(f"   é¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½çº¦6.67GBæ¨¡å‹æ–‡ä»¶")
        print(f"   ä¸‹è½½åä¼šç¼“å­˜åˆ°: ~/.cache/huggingface/")

        start_time = time.time()

        # åŠ è½½Tokenizer
        print("\nâ³ åŠ è½½Tokenizer...")
        self.tokenizer = AutoTokenizer.from_pretrained(
            self.model_name,
            trust_remote_code=True
        )
        print("   âœ… Tokenizer åŠ è½½å®Œæˆ")

        # åŠ è½½æ¨¡å‹
        print("\nâ³ åŠ è½½æ¨¡å‹...")
        model_kwargs = {
            'trust_remote_code': True,
            'use_safetensors': True
        }

        # Flash AttentionåŠ é€Ÿï¼ˆéœ€è¦GPUï¼‰
        if use_flash_attn and self.device == 'cuda':
            try:
                model_kwargs['_attn_implementation'] = 'flash_attention_2'
                print("   ä½¿ç”¨ Flash Attention 2 åŠ é€Ÿ")
            except:
                print("   âš ï¸  Flash Attention ä¸å¯ç”¨ï¼Œä½¿ç”¨æ ‡å‡†æ³¨æ„åŠ›")

        self.model = AutoModel.from_pretrained(
            self.model_name,
            **model_kwargs
        )

        # ç§»åŠ¨åˆ°è®¾å¤‡å¹¶è®¾ç½®ç²¾åº¦
        if self.device == 'cuda':
            self.model = self.model.cuda().to(torch.bfloat16)
            print(f"   âœ… æ¨¡å‹å·²åŠ è½½åˆ°GPU (bfloat16)")
        else:
            self.model = self.model.cpu().to(torch.float32)
            print(f"   âœ… æ¨¡å‹å·²åŠ è½½åˆ°CPU (float32)")

        self.model = self.model.eval()

        load_time = time.time() - start_time
        print(f"\nğŸ‰ æ¨¡å‹åŠ è½½å®Œæˆï¼è€—æ—¶: {load_time:.2f}ç§’")

        return True

    def recognize(
        self,
        image_path: str,
        mode: str = 'ocr',
        resolution: int = 1024,
        output_dir: Optional[str] = None,
        save_result: bool = False
    ) -> str:
        """
        è¯†åˆ«å›¾ç‰‡ä¸­çš„æ–‡å­—

        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            mode: è¯†åˆ«æ¨¡å¼
                - 'ocr': é€šç”¨OCRè¯†åˆ«
                - 'doc2md': æ–‡æ¡£è½¬Markdown
                - 'grounding': å¸¦ä½ç½®ä¿¡æ¯çš„OCR
            resolution: åˆ†è¾¨ç‡ (512/768/1024/1280)
            output_dir: è¾“å‡ºç›®å½•
            save_result: æ˜¯å¦ä¿å­˜ç»“æœ

        Returns:
            è¯†åˆ«å‡ºçš„æ–‡æœ¬
        """
        if not self.model:
            raise RuntimeError("æ¨¡å‹æœªåŠ è½½ï¼Œè¯·å…ˆè°ƒç”¨ load_model()")

        print(f"\nğŸ” å¼€å§‹è¯†åˆ«: {image_path}")
        print(f"   æ¨¡å¼: {mode}")
        print(f"   åˆ†è¾¨ç‡: {resolution}x{resolution}")

        # æ£€æŸ¥å›¾ç‰‡
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"å›¾ç‰‡ä¸å­˜åœ¨: {image_path}")

        # æ„å»ºæç¤ºè¯
        prompts = {
            'ocr': "<image>\nExtract all text from this image.",
            'doc2md': "<image>\n<|grounding|>Convert the document to markdown.",
            'grounding': "<image>\n<|grounding|>Extract text with positions."
        }

        prompt = prompts.get(mode, prompts['ocr'])

        # è®¾ç½®è¾“å‡ºç›®å½•
        if output_dir is None:
            output_dir = './outputs'
        os.makedirs(output_dir, exist_ok=True)

        # æ‰§è¡Œæ¨ç†
        start_time = time.time()

        try:
            result = self.model.infer(
                self.tokenizer,
                prompt=prompt,
                image_file=image_path,
                output_path=output_dir,
                base_size=resolution,     # åŸºç¡€åˆ†è¾¨ç‡
                image_size=640,           # å›¾å—å¤§å°
                crop_mode=True,           # å¯ç”¨è£å‰ªæ¨¡å¼
                save_results=save_result, # æ˜¯å¦ä¿å­˜ç»“æœ
                test_compress=True        # æµ‹è¯•å‹ç¼©
            )

            process_time = time.time() - start_time
            print(f"   âœ… è¯†åˆ«å®Œæˆï¼Œè€—æ—¶: {process_time:.2f}ç§’")

            return result

        except Exception as e:
            print(f"   âŒ è¯†åˆ«å¤±è´¥: {e}")
            raise

    def batch_recognize(
        self,
        image_paths: List[str],
        mode: str = 'ocr',
        resolution: int = 1024,
        output_dir: str = './outputs'
    ) -> List[str]:
        """
        æ‰¹é‡è¯†åˆ«å›¾ç‰‡

        Args:
            image_paths: å›¾ç‰‡è·¯å¾„åˆ—è¡¨
            mode: è¯†åˆ«æ¨¡å¼
            resolution: åˆ†è¾¨ç‡
            output_dir: è¾“å‡ºç›®å½•

        Returns:
            è¯†åˆ«ç»“æœåˆ—è¡¨
        """
        print(f"\nğŸ“¦ æ‰¹é‡è¯†åˆ«æ¨¡å¼")
        print(f"   å…± {len(image_paths)} å¼ å›¾ç‰‡")

        results = []

        for i, image_path in enumerate(image_paths):
            print(f"\nè¿›åº¦: {i+1}/{len(image_paths)}")

            try:
                result = self.recognize(
                    image_path=image_path,
                    mode=mode,
                    resolution=resolution,
                    output_dir=output_dir
                )
                results.append(result)
            except Exception as e:
                print(f"   è·³è¿‡: {e}")
                results.append(None)

        success_count = sum(1 for r in results if r is not None)
        print(f"\nâœ… æ‰¹é‡å¤„ç†å®Œæˆ")
        print(f"   æˆåŠŸ: {success_count}/{len(image_paths)}")

        return results

    def recognize_pdf(
        self,
        pdf_path: str,
        mode: str = 'doc2md',
        resolution: int = 1024,
        output_dir: str = './outputs'
    ) -> str:
        """
        è¯†åˆ«PDFæ–‡æ¡£

        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
            mode: è¯†åˆ«æ¨¡å¼
            resolution: åˆ†è¾¨ç‡
            output_dir: è¾“å‡ºç›®å½•

        Returns:
            åˆå¹¶åçš„è¯†åˆ«ç»“æœ
        """
        try:
            from pdf2image import convert_from_path
        except ImportError:
            raise ImportError("è¯·å®‰è£… pdf2image: pip install pdf2image")

        print(f"\nğŸ“„ PDFè¯†åˆ«æ¨¡å¼")
        print(f"   PDF: {pdf_path}")

        # è½¬æ¢PDFä¸ºå›¾ç‰‡
        print("\nâ³ è½¬æ¢PDFä¸ºå›¾ç‰‡...")
        images = convert_from_path(pdf_path)
        print(f"   âœ… å…± {len(images)} é¡µ")

        os.makedirs(output_dir, exist_ok=True)
        all_text = []

        # é€é¡µå¤„ç†
        for i, image in enumerate(images):
            print(f"\nğŸ“– å¤„ç†ç¬¬ {i+1}/{len(images)} é¡µ")

            # ä¿å­˜ä¸´æ—¶å›¾ç‰‡
            temp_path = os.path.join(output_dir, f"temp_page_{i+1}.jpg")
            image.save(temp_path, 'JPEG')

            # è¯†åˆ«
            try:
                result = self.recognize(
                    image_path=temp_path,
                    mode=mode,
                    resolution=resolution,
                    output_dir=output_dir
                )
                all_text.append(f"\n{'='*60}\nç¬¬ {i+1} é¡µ\n{'='*60}\n{result}")
            except Exception as e:
                print(f"   âš ï¸  ç¬¬ {i+1} é¡µè¯†åˆ«å¤±è´¥: {e}")
                all_text.append(f"\n{'='*60}\nç¬¬ {i+1} é¡µ (è¯†åˆ«å¤±è´¥)\n{'='*60}\n")

            # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            try:
                os.remove(temp_path)
            except:
                pass

        # ä¿å­˜å®Œæ•´ç»“æœ
        output_file = os.path.join(
            output_dir,
            f"{Path(pdf_path).stem}_full_result.md"
        )

        full_text = '\n'.join(all_text)

        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(full_text)

        print(f"\nâœ… PDFå¤„ç†å®Œæˆ")
        print(f"   è¾“å‡ºæ–‡ä»¶: {output_file}")

        return full_text


def demo_single_image():
    """æ¼”ç¤ºï¼šå•å¼ å›¾ç‰‡è¯†åˆ«"""
    print("\n" + "="*70)
    print("ç¤ºä¾‹ 1: å•å¼ å›¾ç‰‡è¯†åˆ«")
    print("="*70)

    # åˆå§‹åŒ–OCR
    ocr = LocalOCR()
    ocr.load_model()

    # è¯†åˆ«å›¾ç‰‡ï¼ˆè¯·æ›¿æ¢ä¸ºä½ çš„å›¾ç‰‡è·¯å¾„ï¼‰
    result = ocr.recognize(
        image_path='test.jpg',
        mode='ocr',
        resolution=1024,
        output_dir='./outputs'
    )

    print(f"\nğŸ“ è¯†åˆ«ç»“æœ:\n{result}")


def demo_batch_images():
    """æ¼”ç¤ºï¼šæ‰¹é‡å›¾ç‰‡è¯†åˆ«"""
    print("\n" + "="*70)
    print("ç¤ºä¾‹ 2: æ‰¹é‡å›¾ç‰‡è¯†åˆ«")
    print("="*70)

    ocr = LocalOCR()
    ocr.load_model()

    # æ‰¹é‡è¯†åˆ«
    image_paths = ['image1.jpg', 'image2.jpg', 'image3.jpg']

    results = ocr.batch_recognize(
        image_paths=image_paths,
        mode='ocr',
        resolution=1024,
        output_dir='./outputs'
    )

    for i, result in enumerate(results):
        if result:
            print(f"\nå›¾ç‰‡ {i+1} ç»“æœ:\n{result[:200]}...")


def demo_pdf():
    """æ¼”ç¤ºï¼šPDFæ–‡æ¡£è¯†åˆ«"""
    print("\n" + "="*70)
    print("ç¤ºä¾‹ 3: PDFæ–‡æ¡£è¯†åˆ«")
    print("="*70)

    ocr = LocalOCR()
    ocr.load_model()

    # è¯†åˆ«PDF
    result = ocr.recognize_pdf(
        pdf_path='document.pdf',
        mode='doc2md',
        resolution=1024,
        output_dir='./outputs'
    )

    print(f"\nğŸ“ PDFè¯†åˆ«å®Œæˆï¼Œå…± {len(result)} å­—ç¬¦")


def demo_different_modes():
    """æ¼”ç¤ºï¼šä¸åŒè¯†åˆ«æ¨¡å¼"""
    print("\n" + "="*70)
    print("ç¤ºä¾‹ 4: ä¸åŒè¯†åˆ«æ¨¡å¼å¯¹æ¯”")
    print("="*70)

    ocr = LocalOCR()
    ocr.load_model()

    image_path = 'test.jpg'

    # æµ‹è¯•ä¸åŒæ¨¡å¼
    modes = ['ocr', 'doc2md', 'grounding']

    for mode in modes:
        print(f"\n{'='*60}")
        print(f"æ¨¡å¼: {mode}")
        print(f"{'='*60}")

        result = ocr.recognize(
            image_path=image_path,
            mode=mode,
            resolution=1024
        )

        print(f"ç»“æœé¢„è§ˆ:\n{result[:300]}...")


if __name__ == "__main__":
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                                                          â•‘
    â•‘         å°è« OCR - æœ¬åœ°éƒ¨ç½²æ¼”ç¤º                          â•‘
    â•‘         åŸºäº DeepSeek-OCR å¼€æºä»£ç                        â•‘
    â•‘         æ— éœ€APIï¼Œå®Œå…¨æœ¬åœ°è¿è¡Œ                            â•‘
    â•‘                                                          â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)

    print("\nè¯·é€‰æ‹©æ¼”ç¤º:")
    print("1. å•å¼ å›¾ç‰‡è¯†åˆ«")
    print("2. æ‰¹é‡å›¾ç‰‡è¯†åˆ«")
    print("3. PDFæ–‡æ¡£è¯†åˆ«")
    print("4. ä¸åŒæ¨¡å¼å¯¹æ¯”")
    print("5. è¿è¡Œæ‰€æœ‰ç¤ºä¾‹")

    choice = input("\nè¯·è¾“å…¥é€‰é¡¹ (1-5): ").strip()

    if choice == '1':
        demo_single_image()
    elif choice == '2':
        demo_batch_images()
    elif choice == '3':
        demo_pdf()
    elif choice == '4':
        demo_different_modes()
    elif choice == '5':
        demo_single_image()
        demo_batch_images()
        demo_pdf()
        demo_different_modes()
    else:
        print("âŒ æ— æ•ˆé€‰é¡¹")

    print("\n" + "="*70)
    print("âœ… æ¼”ç¤ºå®Œæˆ")
    print("="*70)
